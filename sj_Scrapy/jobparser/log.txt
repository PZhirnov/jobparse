2022-02-27 14:12:15 [scrapy.utils.log] INFO: Scrapy 2.5.1 started (bot: jobparser)
2022-02-27 14:12:15 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.1.0, Python 3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 1.1.1m  14 Dec 2021), cryptography 36.0.1, Platform Windows-10-10.0.19042-SP0
2022-02-27 14:12:15 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2022-02-27 14:12:24 [scrapy.utils.log] INFO: Scrapy 2.5.1 started (bot: jobparser)
2022-02-27 14:12:24 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.1.0, Python 3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 1.1.1m  14 Dec 2021), cryptography 36.0.1, Platform Windows-10-10.0.19042-SP0
2022-02-27 14:12:24 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2022-02-27 14:12:24 [scrapy.crawler] INFO: Overridden settings:
{'AUTOTHROTTLE_DEBUG': True,
 'AUTOTHROTTLE_ENABLED': True,
 'AUTOTHROTTLE_MAX_DELAY': 1,
 'AUTOTHROTTLE_START_DELAY': 0.3,
 'BOT_NAME': 'jobparser',
 'DOWNLOAD_DELAY': 0.2,
 'LOG_FILE': 'log.txt',
 'NEWSPIDER_MODULE': 'jobparser.spiders',
 'SPIDER_MODULES': ['jobparser.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, '
               'like Gecko) Chrome/98.0.4758.80 Safari/537.36'}
2022-02-27 14:12:24 [scrapy.extensions.telnet] INFO: Telnet Password: 09da77809e1c74fc
2022-02-27 14:12:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.throttle.AutoThrottle']
2022-02-27 14:12:24 [twisted] CRITICAL: Unhandled error in Deferred:
2022-02-27 14:12:24 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "e:\yandexdisk\_geekbrains_обучение\9_методы сбора и обработки данных\урок 6. scrapy\web_scraping_07_02_2022\venv\lib\site-packages\twisted\internet\defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "e:\yandexdisk\_geekbrains_обучение\9_методы сбора и обработки данных\урок 6. scrapy\web_scraping_07_02_2022\venv\lib\site-packages\scrapy\crawler.py", line 86, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "e:\yandexdisk\_geekbrains_обучение\9_методы сбора и обработки данных\урок 6. scrapy\web_scraping_07_02_2022\venv\lib\site-packages\scrapy\crawler.py", line 98, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "e:\yandexdisk\_geekbrains_обучение\9_методы сбора и обработки данных\урок 6. scrapy\web_scraping_07_02_2022\venv\lib\site-packages\scrapy\spiders\__init__.py", line 50, in from_crawler
    spider = cls(*args, **kwargs)
TypeError: __init__() missing 1 required positional argument: 'query_text'
2022-02-27 18:18:50 [scrapy.utils.log] INFO: Scrapy 2.5.1 started (bot: jobparser)
2022-02-27 18:18:50 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.1.0, Python 3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 1.1.1m  14 Dec 2021), cryptography 36.0.1, Platform Windows-10-10.0.19042-SP0
2022-02-27 18:18:50 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2022-02-27 18:19:16 [scrapy.utils.log] INFO: Scrapy 2.5.1 started (bot: jobparser)
2022-02-27 18:19:16 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.1.0, Python 3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 1.1.1m  14 Dec 2021), cryptography 36.0.1, Platform Windows-10-10.0.19042-SP0
2022-02-27 18:19:16 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2022-02-27 18:19:16 [scrapy.crawler] INFO: Overridden settings:
{'AUTOTHROTTLE_DEBUG': True,
 'AUTOTHROTTLE_ENABLED': True,
 'AUTOTHROTTLE_MAX_DELAY': 1,
 'AUTOTHROTTLE_START_DELAY': 0.3,
 'BOT_NAME': 'jobparser',
 'DOWNLOAD_DELAY': 0.2,
 'LOG_FILE': 'log.txt',
 'NEWSPIDER_MODULE': 'jobparser.spiders',
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['jobparser.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, '
               'like Gecko) Chrome/98.0.4758.80 Safari/537.36'}
2022-02-27 18:19:16 [scrapy.extensions.telnet] INFO: Telnet Password: 285477f2cbf08ed1
2022-02-27 18:19:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.throttle.AutoThrottle']
2022-02-27 18:19:16 [twisted] CRITICAL: Unhandled error in Deferred:
2022-02-27 18:19:16 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "e:\yandexdisk\_geekbrains_обучение\9_методы сбора и обработки данных\урок 6. scrapy\web_scraping_07_02_2022\venv\lib\site-packages\twisted\internet\defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "e:\yandexdisk\_geekbrains_обучение\9_методы сбора и обработки данных\урок 6. scrapy\web_scraping_07_02_2022\venv\lib\site-packages\scrapy\crawler.py", line 86, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "e:\yandexdisk\_geekbrains_обучение\9_методы сбора и обработки данных\урок 6. scrapy\web_scraping_07_02_2022\venv\lib\site-packages\scrapy\crawler.py", line 98, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "e:\yandexdisk\_geekbrains_обучение\9_методы сбора и обработки данных\урок 6. scrapy\web_scraping_07_02_2022\venv\lib\site-packages\scrapy\spiders\__init__.py", line 50, in from_crawler
    spider = cls(*args, **kwargs)
TypeError: __init__() missing 1 required positional argument: 'query_text'
2022-02-28 00:43:12 [scrapy.utils.log] INFO: Scrapy 2.5.1 started (bot: jobparser)
2022-02-28 00:43:12 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.1.0, Python 3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 1.1.1m  14 Dec 2021), cryptography 36.0.1, Platform Windows-10-10.0.19042-SP0
2022-02-28 00:43:12 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2022-02-28 00:43:12 [scrapy.crawler] INFO: Overridden settings:
{'AUTOTHROTTLE_DEBUG': True,
 'AUTOTHROTTLE_ENABLED': True,
 'AUTOTHROTTLE_MAX_DELAY': 1,
 'AUTOTHROTTLE_START_DELAY': 0.3,
 'BOT_NAME': 'jobparser',
 'DOWNLOAD_DELAY': 0.2,
 'LOG_FILE': 'log.txt',
 'NEWSPIDER_MODULE': 'jobparser.spiders',
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['jobparser.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, '
               'like Gecko) Chrome/98.0.4758.80 Safari/537.36'}
2022-02-28 00:43:12 [scrapy.extensions.telnet] INFO: Telnet Password: 74532b23f8ef181f
2022-02-28 00:43:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.throttle.AutoThrottle']
2022-02-28 00:43:12 [twisted] CRITICAL: Unhandled error in Deferred:
2022-02-28 00:43:12 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "e:\yandexdisk\_geekbrains_обучение\9_методы сбора и обработки данных\урок 6. scrapy\web_scraping_07_02_2022\venv\lib\site-packages\twisted\internet\defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "e:\yandexdisk\_geekbrains_обучение\9_методы сбора и обработки данных\урок 6. scrapy\web_scraping_07_02_2022\venv\lib\site-packages\scrapy\crawler.py", line 86, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "e:\yandexdisk\_geekbrains_обучение\9_методы сбора и обработки данных\урок 6. scrapy\web_scraping_07_02_2022\venv\lib\site-packages\scrapy\crawler.py", line 98, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "e:\yandexdisk\_geekbrains_обучение\9_методы сбора и обработки данных\урок 6. scrapy\web_scraping_07_02_2022\venv\lib\site-packages\scrapy\spiders\__init__.py", line 50, in from_crawler
    spider = cls(*args, **kwargs)
TypeError: __init__() missing 1 required positional argument: 'query_text'
